{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 32 # the batch size of input data\n",
    "INPUT_SIZE = 28 # the number in singe time dimension of a single sequence of input data\n",
    "NUM_UNITS = 128  # hide layer size\n",
    "TIME_STEPS = 10  # number of sequence size\n",
    "NUM_LAYERS = 3\n",
    "NUM_MULTI_UNITS = [64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8b0f74cba8b7>:6: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "128\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "(32, 128)\n",
      "(32, 128)\n"
     ]
    }
   ],
   "source": [
    "# RCNNCell, tensorflow 中 RNN 的基本单元, 子类 BasicRNNCell, BasicLSTMCell\n",
    "# (output, cur_state) = cell.call(input, pre_state)\n",
    "# eg -> (y_1, h_1) = cell.call(x_1, h_0)\n",
    "\n",
    "# --------------- test BasicRNNCell-------------\n",
    "rnn_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=128, activation='tanh')\n",
    "print(rnn_cell.state_size)  # 128\n",
    "\n",
    "# --------------- construct two time RNN net work------------------------------\n",
    "# output_1, state_1 = rnn_cell.__call__(inputs=inputs, state=h_0)\n",
    "\n",
    "inputs = tf.placeholder(shape=(32, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "state_0 = rnn_cell.zero_state(BATCH_SIZE, dtype=tf.float32)  # get initial state h_0 of all zeros\n",
    "\n",
    "# ----------------- cell calculate step---------------------------------\n",
    "# output = new_state = act(W * input + U * state + B)\n",
    "# input = (batch_size, input_size)\n",
    "# state = (batch_size, num_units)\n",
    "# W = (input_size, num_units)\n",
    "# U = (num_units, num_units)\n",
    "# B = (batch_size, num_units)\n",
    "# output_size = tf.matmul(input,  W) + tf.matmul(state, U) + B\n",
    "# = (batch_size, num_units) + (batch_size, num_units) + (batch_size, num_units) = (batch_size, num_units)\n",
    "# ------------------- real calculate step---------------\n",
    "# kernel = np.concat((W, U), axis=0)=>([input_size + num_units, num_units])\n",
    "# inputs = tf.concat((input, state), axis=1) => (batch_size, input_size + num_inputs)\n",
    "# bias = (batch_size, num_units)\n",
    "# output_size = tf.matmul(input, kernel) + bias = (batch_size, num_units) + (batch_size, num_units) => (batch_size, num_units)\n",
    "output_1, state_1 = rnn_cell(inputs=inputs, state=state_0)  # output = new_state\n",
    "print(output_1.shape)\n",
    "print(state_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "(32, 128)\n",
      "(32, 128)\n",
      "(32, 128)\n",
      "(32, 128)\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_local_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.local_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# --------------- construct two time RNN net work------------------------------\n",
    "two_step_graph = tf.Graph()\n",
    "with two_step_graph.as_default():\n",
    "    #--------------- test BasicRNNCell-------------\n",
    "    rnn_cell =  tf.nn.rnn_cell.BasicRNNCell(num_units=128, activation='tanh')\n",
    "    print(rnn_cell.state_size)  # 128\n",
    "\n",
    "\n",
    "    # output_1, state_1 = rnn_cell.__call__(inputs=inputs, state=h_0)\n",
    "\n",
    "    inputs_1 = tf.placeholder(shape=(32, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    h_0 = rnn_cell.zero_state(BATCH_SIZE, dtype=tf.float32)  # get initial state h_0 of all zeros\n",
    "    output_1, state_1 = rnn_cell(inputs=inputs_1, state=h_0)  # output = new_state\n",
    "    print(output_1.shape)\n",
    "    print(state_1.shape)\n",
    "    inputs_2 = tf.placeholder(shape=(32, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    output_2, state_2 = rnn_cell(inputs=inputs_2, state=state_1)\n",
    "\n",
    "    print(output_2.shape)\n",
    "    print(state_2.shape)\n",
    "\n",
    "    input_step_batch_1 = tf.random_normal(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32)\n",
    "    input_step_batch_2 = tf.random_normal(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.initialize_local_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_rnn_cell/kernel (156, 128)\n",
      "basic_rnn_cell/bias (128,)\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=two_step_graph) as sess:\n",
    "\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)\n",
    "\n",
    "    input_step_1 = input_step_batch_1.eval()\n",
    "    input_step_2 = input_step_batch_2.eval()\n",
    "\n",
    "    output_1, state_1, output_2, state_2 = sess.run([output_1, state_1, output_2, state_2],\n",
    "                                                    feed_dict={inputs_1: input_step_1, inputs_2:input_step_2})\n",
    "\n",
    "    assert (output_1 == state_1).all()\n",
    "    assert (output_2 == state_2).all()\n",
    "    print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-4a83732116d6>:7: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "(32, 10, 128)\n",
      "(32, 128)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------construct multi step graph---------------------------------------\n",
    "multi_step_graph = tf.Graph()\n",
    "with multi_step_graph.as_default():\n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32)\n",
    "    rnn_cell =  tf.nn.rnn_cell.BasicRNNCell(num_units=NUM_UNITS, activation='tanh')\n",
    "    initial_state = rnn_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell=rnn_cell, inputs=inputs, initial_state=initial_state)\n",
    "    print(outputs.shape) # all steps outputs\n",
    "    print(states.shape)  # last step hidden layer states\n",
    "\n",
    "    input_batch = tf.random_normal(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32)\n",
    "    init_op = tf.group(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn/basic_rnn_cell/kernel (156, 128)\n",
      "rnn/basic_rnn_cell/bias (128,)\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=multi_step_graph) as sess:\n",
    "\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)\n",
    "\n",
    "    input_data = input_batch.eval()\n",
    "\n",
    "    outputs, states = sess.run([outputs, states], feed_dict={inputs: input_data})\n",
    "    outputs_last_step  = outputs[:, -1, :]\n",
    "    assert (outputs_last_step == states).all()\n",
    "    print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_cell(num_units=128, activation='tanh'):\n",
    "\n",
    "    return tf.nn.rnn_cell.BasicRNNCell(num_units=num_units, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-9ec169db9407>:6: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "(64, 128, 256)\n",
      "(32, 256)\n",
      "(32, 64) (32, 128) (32, 256)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------construct multi layer graph----------------------------\n",
    "multi_layer_graph = tf.Graph()\n",
    "with multi_layer_graph.as_default():\n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32)\n",
    "    cells = [get_rnn_cell(NUM_MULTI_UNITS[i]) for i in range(NUM_LAYERS)]\n",
    "    rnn_cells = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "    print(rnn_cells.state_size) # (64, 128, 256)\n",
    "    initial_state = rnn_cells.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "\n",
    "    # ----------------MultiRNNCell calculate step------------------\n",
    "    # inputs = (batch_size, input_size)\n",
    "    # states = [(batch_size, num_units_1), (batch_size, num_units_2), (batch_size, num_units_3)]\n",
    "    # new_states = []\n",
    "    # step 1 : output_1, h_1 = cell(inputs, states[0])\n",
    "    #          new_states.append(h_1)\n",
    "    # step 2 : output_2, h_2 =  cell(output_1, state[1])\n",
    "    #          new_states.append(h_2)\n",
    "    # step 3 : output_3, h_3 =  cell(output_2, state[2])\n",
    "    #          new_states.append(h_3)\n",
    "    # return output_3, new_states\n",
    "    outputs, states = rnn_cells(inputs=inputs, state=initial_state)\n",
    "    print(outputs.shape)  # (32, 256)\n",
    "    print(states[0].shape, states[1].shape, states[2].shape)  # (32, 64) (32, 128) (32, 256)\n",
    "\n",
    "    input_batch = tf.random_normal(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=multi_layer_graph) as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    input_data = input_batch.eval()\n",
    "    outputs, states = sess.run([outputs, states], feed_dict={inputs: input_data})\n",
    "    assert (outputs == states[-1]).all()\n",
    "    print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 256)\n",
      "(32, 10, 256)\n",
      "(32, 64) (32, 128) (32, 256)\n"
     ]
    }
   ],
   "source": [
    "# ---------------construct multi step multi layer RNN---------------\n",
    "# construct multi step multi layer graph\n",
    "multi_step_multi_layer_graph = tf.Graph()\n",
    "with multi_step_multi_layer_graph.as_default():\n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32)\n",
    "    cells = [get_rnn_cell(NUM_MULTI_UNITS[i]) for i in range(NUM_LAYERS)]\n",
    "\n",
    "    rnn_cells = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "    print(rnn_cells.state_size)  # (64, 128, 256)\n",
    "    initial_state = rnn_cells.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell=rnn_cells,\n",
    "                                        inputs=inputs,\n",
    "                                        initial_state=initial_state)\n",
    "    print(outputs.shape)  # (32, 256)\n",
    "    print(states[0].shape, states[1].shape, states[2].shape)  # (32, 64) (32, 128) (32, 256)\n",
    "\n",
    "    input_batch = tf.random_normal(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn/multi_rnn_cell/cell_0/basic_rnn_cell/kernel (92, 64)\n",
      "rnn/multi_rnn_cell/cell_0/basic_rnn_cell/bias (64,)\n",
      "rnn/multi_rnn_cell/cell_1/basic_rnn_cell/kernel (192, 128)\n",
      "rnn/multi_rnn_cell/cell_1/basic_rnn_cell/bias (128,)\n",
      "rnn/multi_rnn_cell/cell_2/basic_rnn_cell/kernel (384, 256)\n",
      "rnn/multi_rnn_cell/cell_2/basic_rnn_cell/bias (256,)\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=multi_step_multi_layer_graph) as sess:\n",
    "\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)\n",
    "\n",
    "    input_data = input_batch.eval()\n",
    "\n",
    "    outputs, states = sess.run([outputs, states], feed_dict={inputs: input_data})\n",
    "    outputs_last_step  = outputs[:, -1, :]\n",
    "    states_last_layer = states[-1]\n",
    "\n",
    "    assert (outputs_last_step == states_last_layer).all()\n",
    "    print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-d276ab155ac9>:18: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "(32, 10, 128)\n",
      "(32, 10, 128)\n",
      "(32, 128)\n",
      "(32, 128)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------construct bidirectional RNN-------------------------------\n",
    "# from tensorflow.python.ops.rnn import bidirectional_dynamic_rnn\n",
    "bidirectional_graph = tf.Graph()\n",
    "\n",
    "with bidirectional_graph.as_default():\n",
    "    cell_forward = get_rnn_cell(NUM_UNITS)\n",
    "    cell_backward = get_rnn_cell(NUM_UNITS)\n",
    "\n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32, name=\"input_data\")\n",
    "\n",
    "    status_forward = cell_forward.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "    status_backward = cell_backward.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "\n",
    "    (fw_outputs, bw_outputs), (fw_status, bw_status) = tf.nn.bidirectional_dynamic_rnn(cell_fw=cell_forward,\n",
    "                                                      cell_bw=cell_backward,\n",
    "                                                      initial_state_fw=status_forward,\n",
    "                                                      initial_state_bw=status_backward,\n",
    "                                                      inputs=inputs)\n",
    "\n",
    "    print(fw_outputs.shape)\n",
    "    print(bw_outputs.shape)\n",
    "    print(fw_status.shape)\n",
    "    print(bw_status.shape)\n",
    "\n",
    "    input_batch = tf.random_normal(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional_rnn/fw/basic_rnn_cell/kernel (156, 128)\n",
      "bidirectional_rnn/fw/basic_rnn_cell/bias (128,)\n",
      "bidirectional_rnn/bw/basic_rnn_cell/kernel (156, 128)\n",
      "bidirectional_rnn/bw/basic_rnn_cell/bias (128,)\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=bidirectional_graph) as sess:\n",
    "\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)\n",
    "\n",
    "    input_data = input_batch.eval()\n",
    "\n",
    "    fw_outputs, bw_outputs, fw_status, bw_status = sess.run([fw_outputs, bw_outputs, fw_status, bw_status],\n",
    "                                                            feed_dict={inputs: input_data})\n",
    "    fw_output_first_step = fw_outputs[:, 0, :]\n",
    "    fw_output_last_step  = fw_outputs[:, -1, :]\n",
    "\n",
    "    bw_output_first_step = bw_outputs[:, 0, :]  # due to output reverse to recover normal sequence\n",
    "    bw_output_last_step = bw_outputs[:, -1, :]\n",
    "\n",
    "    assert (fw_output_last_step == fw_status).all()\n",
    "    assert (bw_output_first_step == bw_status).all()\n",
    "    print('Done !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
