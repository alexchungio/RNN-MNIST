{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 32 # the batch size of input data\n",
    "INPUT_SIZE = 28 # the number in singe time dimension of a single sequence of input data\n",
    "NUM_UNITS = 128  # hide layer size\n",
    "TIME_STEPS = 10  # number of sequence size\n",
    "NUM_LAYERS = 3\n",
    "NUM_MULTI_UNITS = [64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru_cell(num_units=128, activation='tanh'):\n",
    "\n",
    "    return tf.nn.rnn_cell.GRUCell(num_units=num_units, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-cbe5d78f27d1>:3: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "128\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "(32, 128)\n",
      "(32, 128)\n"
     ]
    }
   ],
   "source": [
    "gru_cell = get_gru_cell(NUM_UNITS)\n",
    "# c => carry state  h => hide state\n",
    "print(gru_cell.state_size) # 128\n",
    "\n",
    "inputs = tf.placeholder(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32, name=\"inputs_data\")\n",
    "\n",
    "state_0 =  gru_cell.zero_state(batch_size=BATCH_SIZE, dtype=tf.float32)\n",
    "# ----------------- cell calculate step---------------------------------\n",
    "#  w_r => reset_gate, w_u => update_gate  w_c => candidate\n",
    "# input = (batch_size, input_size)\n",
    "# state = (batch_size, num_units)\n",
    "# w_r = w_u = w_c = (input_size + num_units, num_units)\n",
    "# step 1 calculate r and u\n",
    "# r = tf.matmul(tf.concat((input, state), axis=1), w_r) => (batch_size, num_units)\n",
    "# u = tf.matmul(tf.concat((input, state), axis=1), w_u) => (batch_size, num_units)\n",
    "\n",
    "# step 2 calculate c(candidate)\n",
    "# c = tf.matmul(tf.concat((input, r), axis=1), w_c) => (batch_size, num_units)\n",
    "# new_h = tf.multiply(u, h) + tf.multiply(1-u, c)\n",
    "\n",
    "# return new_h, new_h\n",
    "# ------------------- real calculate step---------------\n",
    "# inputs = tf.concat((input, state), axis=1) => (batch_size, input_size + num_inputs)\n",
    "# gate_kernel = (input_size+num_units, num_units * 2)\n",
    "# gate__bias = (num_units*2,)\n",
    "# candidate_kernel = (input_size+num_units, num_units)\n",
    "# candidate_kernel = (num_units,)\n",
    "# gate_inputs = tf.matmul(inputs, gate_kernel)\n",
    "# r, u = split(value=gate_inputs, num_or_size_splits=2, axis=-1)\n",
    "# c = tf.matmul(tf.concat((input, r), axis=1), candidate_kernel)\n",
    "# new_h = tf.multiply(u, state) + tf.multiply(1-u, c)\n",
    "# return new_h, new_h\n",
    "outputs, states = gru_cell(inputs=inputs, state=state_0)  # outputs = states\n",
    "print(outputs.shape)\n",
    "print(states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128)\n",
      "(32, 128)\n",
      "WARNING:tensorflow:From /home/alex/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_local_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.local_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------construct two step gru------------------------------\n",
    "tow_step_graph = tf.Graph()\n",
    "with tow_step_graph.as_default():\n",
    "    gru_cell = get_gru_cell(num_units=NUM_UNITS)\n",
    "\n",
    "    input_1 = tf.placeholder(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32, name=\"inputs_1\")\n",
    "    input_2 = tf.placeholder(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32, name=\"inputs_2\")\n",
    "\n",
    "    state_0 = gru_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "\n",
    "    output_1, state_1 = gru_cell(inputs=input_1, state=state_0)\n",
    "\n",
    "    output_2, state_2 = gru_cell(inputs=input_2, state=state_1)\n",
    "    print(output_2.shape)\n",
    "    print(state_2.shape)\n",
    "\n",
    "\n",
    "    input_step_batch_1 = tf.random_normal(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32)\n",
    "    input_step_batch_2 = tf.random_normal(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.initialize_local_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=tow_step_graph) as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)  # (input_size + num_units, num_units*4)\n",
    "\n",
    "    input_data_1 = input_step_batch_1.eval()\n",
    "    input_data_2 = input_step_batch_2.eval()\n",
    "\n",
    "    output_2, state_2 = sess.run([output_2, state_2], feed_dict={input_1: input_data_1,\n",
    "                                                                 input_2: input_data_2})\n",
    "\n",
    "    assert (output_2 == state_2).all()  # h_2 == state_2.h\n",
    "    print('Two step test done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------construct multi step gru------------------------------\n",
    "# tf.nn.dynamic_rnn\n",
    "multi_step_graph = tf.Graph()\n",
    "with multi_step_graph.as_default():\n",
    "    gru_cell = get_gru_cell(num_units=NUM_UNITS)\n",
    "\n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32, name=\"inputs_1\")\n",
    "\n",
    "    state_0 = gru_cell.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell=gru_cell, inputs=inputs, initial_state=state_0)\n",
    "\n",
    "    print(outputs.shape)\n",
    "    print(states.shape)\n",
    "\n",
    "    input_step_batch = tf.random_normal(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.initialize_local_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=multi_step_graph) as sess:\n",
    "    sess.run(init_op)\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)  # # (input_size + num_units, num_units*4)\n",
    "    input_data = input_step_batch.eval()\n",
    "\n",
    "    outputs, states = sess.run([outputs, states], feed_dict={inputs: input_data})\n",
    "    outputs_last_step = outputs[:, -1, :]\n",
    "    assert (outputs_last_step == states).all()  # h_2 == state_2.h\n",
    "    print('Multi step test done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------construct multi layer gru------------------------------\n",
    "multi_layer_graph = tf.Graph()\n",
    "with multi_layer_graph.as_default():\n",
    "\n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32, name=\"inputs_1\")\n",
    "\n",
    "    cells = [get_gru_cell(num_units=NUM_MULTI_UNITS[i]) for i in range(NUM_LAYERS)]\n",
    "\n",
    "    gru_cells = tf.nn.rnn_cell.MultiRNNCell(cells=cells, state_is_tuple=True)\n",
    "\n",
    "    state_0 = gru_cells.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "\n",
    "    outputs, states = gru_cells(inputs=inputs, state=state_0)\n",
    "\n",
    "    print(outputs.shape)\n",
    "    print(states[-1].shape)\n",
    "\n",
    "    input_step_batch = tf.random_normal(shape=(BATCH_SIZE, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.initialize_local_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=multi_layer_graph) as sess:\n",
    "    sess.run(init_op)\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)  # # (input_size + num_units, num_units*4)\n",
    "    input_data = input_step_batch.eval()\n",
    "\n",
    "    outputs, states = sess.run([outputs, states], feed_dict={inputs: input_data})\n",
    "\n",
    "    assert (outputs == states[-1]).all()  # h_2 == state_2.h\n",
    "    print('Multi layer test done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ----------------------construct multi step multi layer gru------------------------------\n",
    "multi_step_multi_layer_graph = tf.Graph()\n",
    "with multi_step_multi_layer_graph.as_default():\n",
    "\n",
    "    inputs = tf.placeholder(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32, name=\"inputs_1\")\n",
    "\n",
    "    cells = [get_gru_cell(num_units=NUM_MULTI_UNITS[i]) for i in range(NUM_LAYERS)]\n",
    "\n",
    "    gru_cells = tf.nn.rnn_cell.MultiRNNCell(cells=cells, state_is_tuple=True)\n",
    "\n",
    "    state_0 = gru_cells.zero_state(BATCH_SIZE, dtype=tf.float32)\n",
    "\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell=gru_cells, inputs=inputs, initial_state=state_0)\n",
    "\n",
    "    print(outputs.shape)\n",
    "    print(states[-1].shape)\n",
    "\n",
    "\n",
    "    input_step_batch = tf.random_normal(shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE), dtype=tf.float32)\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(),\n",
    "                       tf.initialize_local_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=multi_step_multi_layer_graph) as sess:\n",
    "    sess.run(init_op)\n",
    "    for var in tf.global_variables():\n",
    "        print(var.op.name, var.shape)  # # (input_size + num_units, num_units*4)\n",
    "    input_data = input_step_batch.eval()\n",
    "\n",
    "    outputs, states = sess.run([outputs, states], feed_dict={inputs: input_data})\n",
    "\n",
    "    outputs_last_step = outputs[:, -1, :]\n",
    "    states_last_layer = states[-1]\n",
    "\n",
    "    assert (outputs_last_step == states_last_layer).all()  # h_2 == state_2.h\n",
    "    print('Multi step multi layer test done !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
